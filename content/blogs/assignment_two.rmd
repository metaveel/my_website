---
title: "Excess rentals in Transport for London bike sharing"
date: '2021-10-17'
description: Excess rentals in Transport for London bike sharing
draft: no
image: bike.jpg
keywords: ''
slug: assignment_two
categories:
- ''
- ''
---


```{r, setup, echo=FALSE}
knitr::opts_chunk$set(
  message = FALSE, 
  warning = FALSE, 
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
options(digits = 3)

# default figure size
knitr::opts_chunk$set(
  fig.width=6.75, 
  fig.height=6.75,
  fig.align = "center"
)
```


```{r load-libraries, include=FALSE, cache = TRUE}

library(tidyverse)  # Load ggplot2, dplyr, and all the other tidyverse packages
library(mosaic)
library(ggthemes)
library(lubridate)
library(here)
library(skimr)
library(janitor)
library(httr)
library(readxl)
library(vroom)
library(infer)
library(rvest)
library(fivethirtyeight)
library(tidyquant)

```


# My Second R Assigment 

The following graphs are about the excess rentals (the difference between actual rental and expected rental) in Transport for London ("TFL") bike sharing during 2016 to 2021


## Downloading and cleaning data
We download the latest TFL data and read it as a dataframe. Then we change the date variables to get year, month and week. 

```{r get_tfl_data, cache=TRUE}
url <- "https://data.london.gov.uk/download/number-bicycle-hires/ac29363e-e0cb-47cc-a97a-e216d900a6b0/tfl-daily-cycle-hires.xlsx"

# Download TFL data to temporary file
httr::GET(url, write_disk(bike.temp <- tempfile(fileext = ".xlsx")))

# Use read_excel to read it as dataframe
bike0 <- read_excel(bike.temp,
                   sheet = "Data",
                   range = cell_cols("A:B"))

# change dates to get year, month, and week
bike <- bike0 %>% 
  clean_names() %>% 
  rename (bikes_hired = number_of_bicycle_hires) %>% 
  mutate (year = year(day),
          month = lubridate::month(day, label = TRUE),
          week = isoweek(day))
```

**Look at May and Jun and compare 2020 with the previous years. What's happening?**

Looking at the facet grid chart with the number of bikes hired by month and year, we see a much smaller peak in May and June 2020 compared to previous years. What we see is that number of days with a high number of rentals, aprx. 30-50k is much less than previous years. The number of bikes rented each day is much more inconsistent and varies along the entire spectrum. This is a result of COVID lockdown, where bike usage patterns changed. We see that the rentals take up again in July, when lockdown was lifted, and the distribution starts to normalize.  

## Reproducing graphs
We will reproduce the following two graphs.

We are creating the first plot:
```{r tfl_plot_1, cache=TRUE}
data_bike <-bike %>%
  group_by(month,year) %>% #grouping by month and year
  summarize(actual_rentals=mean(bikes_hired)) #selecting by the number of bikes hired to create the number of bikes hired by every month of each year

expected_bike <-data_bike %>%
  group_by(month) %>% #grouping by month
  filter(year %in% c(2016,2017,2018,2019)) %>% #filtering the months we want to analyse
  summarize(expected_rentals=mean(actual_rentals)) #selecting by the number of bikes hired to create the number of bikes hired by every month overall no matter the year

df3 <- left_join(data_bike, expected_bike, by = c("month")) %>% 
  filter(year %in% c(2016,2017,2018,2019,2020,2021)) %>% #filtering the months we want to analyse
  mutate(excess_rentals = actual_rentals - expected_rentals, #using the mutate function to obtain the excess rentals
         up = ifelse(actual_rentals>expected_rentals, actual_rentals, expected_rentals), #using the mutate function to obtain the excess rentals
         down = ifelse(actual_rentals<expected_rentals, actual_rentals, expected_rentals)) #using the mutate function to obtain the deficit rentals

ggplot(df3,aes(x=month,y=actual_rentals,group=1))+
  geom_line(colour="black",size=0.2)+ #plotting the rentals observed by month
  geom_line(aes(x=month,y=expected_rentals,group=1),colour="blue",size=1)+ #plotting the expected rentals by month
  geom_ribbon(aes(ymin=actual_rentals,ymax=up),fill="#CB454A",alpha=0.4)+ #filling in green the excess of bike rentals
  geom_ribbon(aes(ymin=down,ymax=actual_rentals),fill="#7DCD85",alpha=0.4)  + #filling in red the deficit of bike rentals
  facet_wrap(~year)+ #faceting by year
  theme_bw()+
  labs(title="Monthly changes in Tfl bike rentals",
       subtitle = "Change from monthly average shown in blue
and calculated between 2016-2019",
         y="Bike rentals",x="",caption="Source:Tfl, London Data Store")+
  theme(legend.position = "none", #setting a theme to make the graph more easily readable
        legend.background=element_blank(),
        plot.title=element_text(size=6,face="bold"),
        axis.ticks=element_blank(),
        axis.text=element_text(size=4),
        strip.text=element_text(size=4),
        axis.title=element_text(size=4,face="bold"),
        plot.subtitle=element_text(size=4),
        plot.caption = element_text(size=4),
        panel.border = element_rect(colour="white"),
        strip.background = element_rect(color="transparent",fill="transparent"))

```


We are creating the second plot:

```{r tfl_plot_2, cache=TRUE}
df4 <-bike %>%
  group_by(year,week) %>% #grouping by month
  filter(year>2015,week!=53) %>% #filtering for the year we are interested in and setting the number of weeks
  summarize(weekly_average=mean(bikes_hired)) #creating the average mean of bikes hired by every week of each year

df5 <-df4 %>%
  group_by(week) %>% #grouping by week
  filter(year>2015,week!=53) %>% #filtering for the year we are interested in and setting the number of weeks
  summarize(weekly_average_overall=mean(weekly_average)) #creating the average mean of bikes hired every week no matter the year

df6 <- left_join(df4, df5, by = c("week"))%>% 
  mutate(week_diff = ((weekly_average-weekly_average_overall)/weekly_average_overall))%>% #creating the difference of expected bike rentals vs actual bikes rental
  select(year, week, week_diff) %>% #selecting for the columns that we will use
  mutate(positive=if_else(0<week_diff,week_diff,0), #creating a function to calculate the bike rentals deficit
         negative=if_else(0>week_diff,week_diff,0),colorID=if_else(0<week_diff,"#7DCD85","#CB454A"))  #creating a function to calculate the bike rentals excess

ggplot(df6,aes(x=week,y=week_diff,ymin=-0.6,ymax=1))+
  geom_line(group = 1) + #plotting the bike rentals
  geom_rug(data = df6, aes(color=colorID, alpha=0.4), sides = "b") + 
  geom_ribbon(aes(ymin=0, ymax=negative), fill="#CB454A", alpha= 0.4)+ #colouring the deficit of bikes rentals in red
  geom_ribbon(aes(ymin=positive, ymax=0), fill="#7DCD85", alpha= 0.4)+ #colouring the excess of bikes rentals in green
  facet_wrap(~year)+ #faceting by year
  scale_y_continuous(labels=scales::percent)+ #scaling by percent for increased readibility
  scale_color_manual(values=c("#7DCD85","#CB454A"))+
  theme_bw()+
  geom_rect(aes(xmin=13,xmax=26,ymin=-0.80,ymax=1.20), alpha=0.01, fill="gray")+ #colouring Q2 in gray
  geom_rect(aes(xmin=39,xmax=52,ymin=-0.80,ymax=1.20), alpha=0.01, fill="gray")+ #colouring G4 in gray
  labs(title="Weekly changes in Tfl bike rentals",
       subtitle = "Change from weekly average
calculated between 2016-2019",
         y="",x="week",caption="Source: Tfl, London Data Store")+
  theme(legend.position = "none", #setting a theme for increased readibility
        legend.background=element_blank(),
        plot.title=element_text(size=6,face="bold"),
        axis.ticks=element_blank(),
        axis.text=element_text(size=4),
        strip.text=element_text(size=4),
        axis.title=element_text(size=4,face="bold"),
        plot.subtitle=element_text(size=4),
        plot.caption = element_text(size=4),
        panel.border = element_rect(colour="white"),
        strip.background = element_rect(color="transparent",fill="transparent"))

```


**Should you use the mean or the median to calculate your expected rentals? Why?**

We use mean because we are looking at normal distributions. The mean is often heavily influenced by outliers, however, our data does not contain outliers. The median is usually used for skewed distributions or data with many outliers. The expected outcome value is often referred to as the “long-term” average or mean. Over the long term of doing sampling over and over, you would expect this average. 




